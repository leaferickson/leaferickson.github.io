---
layout: post
title: Project 2
---

For my second project, I predicted Pro Football stats for the three main skill positions (quarterack, running back, and wide reveiver) using only their college stats. The main idea of the project was to see two different things. The first, was to use a puerly predictive model to see how well it is possible to predict pro performance at each position. The second was to use an explanatory model to see what stats are more or less important in explaining pro performance.

Data:

To do this, I used BeautifulSoup to scrape data from [pro](https://www.pro-football-reference.com/) and [college](https://www.sports-reference.com/cfb/) football-reference.com.This took me more than a few tries, and I ran into a few problems with players who played different position in pro and in college, players who did not have stats for college, players whose html tables did not conform to the norm, etc. I learned from experience that the try, except loop is your friend, and that building your scraping tool to look for specific id's and page section's is by far the best way to head off the problems that I ran into.

In addition to the basic continuous variables like yards, touchdowns, rushes/catches/completions, etc., I included one categorical variable: playing in a Power 5 Conference. I used my domain knowledge to decide that grouping players into Power Conferences and non-power Conferences was the best way to account for the unevenness in the level of competition amongst the different schools. The hard part of this was to account for which conferences were power conferences historically. I included {"AAWU", "American", "ACC", "Big 12", "Big 8", "Big Ten", "Big East", "Pac-12", "Pac-10", "Pac-8", "PCC", "SEC", "SWC", "Ind"} as "Power Conferences," and anything outside of those conferences to be a minor conference with inferior competition (and therefore inflated stat lines). I also included year graduated (or final college year) as another continuous variable, in order to account for any changes over time. While Year never came up as significant on its own, it did become significant as an interaction term with other data.

Method:

This project was by far the most intense data cleaning I have ever had to do. Because the data was scraped from online, and not given to me in a nice csv or txt file, there were all sorts of anomalies in the data. Especially before I learned to refine my data scraping, when I was simply trying to get a minimal viable product going, the data that I gathered had all sorts of outliers. Players would have 1000 touchdowns, have a perfect passer rating because they only ever threw one pass, some players retired early (depressing their career statistics) or got injured midway through a prolific career. I was forced to make decisions about minimum numbers of passes, catches, and runs, to be considered a viable sample for my dataset, and had to constantly check histogram distributions of each feature and often of two inter-related features to ensure that all my data actually made sense and was real data.

As my final step before I could even begin my analysis, I had to come up with some sort of value function. This was actually the hardest part of the project, as debates still rage online of how to best evaluate someone's NFL career. Some of the hardest questions to answer had to do with the effect of time. At the lower end of the NFL scale (for those just making it into games and onto rosters), starting in more games would seem to indicate that the player had higher value (since they stuck around longer in the league). However, at the other end of the NFL spectrum (players with the hhighest value), there are players such as Calvin Johnson or Barry Sanders who cut their careers short to enjoy their success and life after the NFL. They are clearly still better players than those who played longer but at a lower level. 

This is where I wish that I had more time, as I believe that the ideal solution would have been to have some sort of function that values playing more games up to a certain point (say 3/4 of the sample mean), but then doesn't give any value to games played after that, or gives decreasing value to those games. Some sort of log function on games played would probably be the closest to ideal.

Unfortunately, the time for my project was somewhat compressed, and once I came up with a value function that was mostly good, I decided to stick with that so that I could move on to the actual analysis. The function that I ended up using is: (Yards + (50 * TouchDowns - 1/2 * Fumbles)) / (1/2 * GamesPlayed). This was using the lifetime professional stats of both receivers and running backs. 

Analysis and Results:

For my analysis, I looked at both a player's cumulative college stats, and the stats only over the course of their final year in college, as I was not initially sure which one would have a greater effect, and especially if one might have more explanatory power, while the other had more predictive power. Interestingly, for receivers and running backs I found that cumulative stats held more explanatory power, and accordingly used those in my predictive model. Final year statistics only actually had more overall predictive power, however, than the cumulative college statistics. Even more interestingly, the sitaution was reversed for quarterbacks, where cumulative stats held for predictive power, but senior stats had more explanatory power.

For my explanatory models, I used a cutoff of 10% for my significance levels. I used only linear regression, since I wanted the results to be interpretable. Regularized models can result in unstable coefficients, and this is especially true with my dataset since there is a large amount of collinearity between different metrics (rushes, yards, and touchdowns are all correlated significantly for example). This is one of the limits of the explanatory models, as this breaks the OLS assumptions. Unfortunately, there is no good way to use an instrumental variable to separate out rushes from yards or yards from touchdowns, so if you want to predict professional performance, you have to be willing to accept this violation of the OLS assumptions.

For receivers, my explanatory model ended up being: Value ~ Yards + Receptions + Touchdowns + Conference. This model explained 12.2 percent of pro performance using adjusted R-squared. This was the only position in which playing in a power conference came up as a significant variable, so stay away from small schools at the receiver position. My predictive models for receiver did not show any significant improvement in predictive power for my test dataset, so I decided to only use an explanatory model for receivers to keep the model simple and the results interpretable.

For running backs, my explanatory model was: Value ~ Yards + Touchdowns + Attempts * Year. As expected, touchdowns and yards still factor in. The interesting part of the model is the interaction term between attempts and year. The coefficient for this term was positive, so this means that as time goes on, it becomes more and more important to get a running back who has more college experience. This may be related to the movement to get youth running backs on cheap rookie contracts, as well as the young age at which running backs begin to wear down. This means that running backs are not in the league for very long, and they are expected to make an impact immediately out of college. The most productive backs therefore need more college experience and time spent learning their craft to be able to make that immediate impact at the pro level. This model was able to explain 15.7% of the variation in running back value scores.

For quarterbacks, my explanatory model was: Value ~ Attempts + Completions + Percentage * Year. The interaction term is again the interesting part here, as it appears that being able to throw accurately while still in college is becoming more and more important as time goes on. This model explained 18% of the variance in QB lifetime professional passer ratings, and I used the final year of college  stats only to explain this (not cumulative stats). 

The predictive models ended up improving on the predictive power of the explanatory models only slightly. For running backs, I used an Elastic Net model using the same inputs as the explanatory model as got a 16.6% reduction in Mean Squared Error. For quarterbacks I did a linear regression using all available statistics, and got a 21.7% MSE reduction. Perhaps the most intersting thing about the whole project was the fact that those positions with better explanatory models not only also had better predictive models, but the predictive models experienced a higher percentage of error reduction if the original explanatory model was already ahead of other positions. Thus, while the quarterback explanatory model was more effective than the wide receiever model, the quarterback predictive model had an even wider gap with the receiver predictive model than the explanatory models had.


Methods used:
* Regression
	* Scikitlearn and statsmodels
	* Linear Regression
	* Regularized Regression
		* Lasso, Ridge, and ElasticNet
* Data Scraping
	* BeautifulSoup
	* Selenium


